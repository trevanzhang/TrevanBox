#!/usr/bin/env python3
"""
TrevanBox é«˜çº§åº¦é‡åˆ†æå·¥å…·
æä¾›æ·±åº¦çš„ç³»ç»Ÿå¥åº·åº¦åˆ†æå’Œè¶‹åŠ¿è¿½è¸ªåŠŸèƒ½
"""

import os
import json
import re
import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict
import argparse

@dataclass
class SystemMetrics:
    """ç³»ç»Ÿåº¦é‡æ•°æ®ç»“æ„"""
    date: str
    total_files: int
    para_distribution: Dict[str, Dict[str, float]]
    pending_items: int
    oldest_pending_age: int
    overall_health: float
    content_quality: Dict[str, float]
    efficiency_metrics: Dict[str, float]
    growth_metrics: Dict[str, float]

class TrevanBoxMetricsAnalyzer:
    """TrevanBox åº¦é‡åˆ†æå™¨"""

    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.reports_dir = self.base_path / "docs" / "reports"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        self.history_file = self.reports_dir / "metrics_history.json"

        # PARAç›®å½•é…ç½®
        self.para_config = {
            "1-Projects": {"ideal_range": (15, 25), "weight": 0.3},
            "2-Areas": {"ideal_range": (25, 35), "weight": 0.25},
            "3-Resources": {"ideal_range": (35, 45), "weight": 0.25},
            "4-Archives": {"ideal_range": (5, 15), "weight": 0.2}
        }

    def analyze_system(self) -> SystemMetrics:
        """åˆ†æç³»ç»ŸçŠ¶æ€ï¼Œè¿”å›åº¦é‡æ•°æ®"""
        print("ğŸ” å¼€å§‹åˆ†æç³»ç»ŸçŠ¶æ€...")

        # åŸºç¡€ç»Ÿè®¡
        para_stats = self._analyze_para_distribution()
        pending_stats = self._analyze_pending_items()

        # å†…å®¹è´¨é‡åˆ†æ
        content_quality = self._analyze_content_quality()

        # æ•ˆç‡æŒ‡æ ‡åˆ†æ
        efficiency_metrics = self._analyze_efficiency()

        # æˆé•¿æŒ‡æ ‡åˆ†æ
        growth_metrics = self._analyze_growth()

        # è®¡ç®—æ€»ä½“å¥åº·åº¦
        overall_health = self._calculate_overall_health(para_stats, content_quality, efficiency_metrics)

        metrics = SystemMetrics(
            date=datetime.datetime.now().isoformat(),
            total_files=sum(stats["count"] for stats in para_stats.values()),
            para_distribution=para_stats,
            pending_items=pending_stats["count"],
            oldest_pending_age=pending_stats["oldest_age"],
            overall_health=overall_health,
            content_quality=content_quality,
            efficiency_metrics=efficiency_metrics,
            growth_metrics=growth_metrics
        )

        print(f"âœ… åˆ†æå®Œæˆï¼Œæ€»ä½“å¥åº·åº¦: {overall_health:.1f}/100")
        return metrics

    def _analyze_para_distribution(self) -> Dict[str, Dict[str, float]]:
        """åˆ†æPARAåˆ†å¸ƒ"""
        print("ğŸ“ åˆ†æPARAåˆ†å¸ƒ...")

        distribution = {}
        total_files = 0

        # ç»Ÿè®¡å„ç±»åˆ«æ–‡ä»¶æ•°é‡
        for category in self.para_config.keys():
            count = self._count_markdown_files(category)
            size = self._get_directory_size(category)

            distribution[category] = {
                "count": count,
                "size_mb": size,
                "ratio": 0.0,  # ç¨åè®¡ç®—
                "health": 0.0   # ç¨åè®¡ç®—
            }
            total_files += count

        # è®¡ç®—æ¯”ä¾‹å’Œå¥åº·åº¦
        for category, stats in distribution.items():
            if total_files > 0:
                stats["ratio"] = (stats["count"] / total_files) * 100

            ideal_min, ideal_max = self.para_config[category]["ideal_range"]
            stats["health"] = self._calculate_range_score(stats["ratio"], ideal_min, ideal_max)

        return distribution

    def _analyze_pending_items(self) -> Dict[str, int]:
        """åˆ†æå¾…å¤„ç†é¡¹ç›®"""
        print("â³ åˆ†æå¾…å¤„ç†é¡¹ç›®...")

        pending_dir = self.base_path / "0-Inbox" / "pending"
        if not pending_dir.exists():
            return {"count": 0, "oldest_age": 0}

        pending_files = list(pending_dir.glob("**/*.md"))
        count = len(pending_files)

        if count == 0:
            return {"count": 0, "oldest_age": 0}

        # è®¡ç®—æœ€æ—§æ–‡ä»¶å¹´é¾„
        current_time = datetime.datetime.now().timestamp()
        oldest_timestamp = min(f.stat().st_mtime for f in pending_files)
        oldest_age = int((current_time - oldest_timestamp) / 86400)  # è½¬æ¢ä¸ºå¤©

        return {"count": count, "oldest_age": oldest_age}

    def _analyze_content_quality(self) -> Dict[str, float]:
        """åˆ†æå†…å®¹è´¨é‡"""
        print("ğŸ“ åˆ†æå†…å®¹è´¨é‡...")

        total_files = 0
        files_with_metadata = 0
        files_with_links = 0
        total_links = 0
        recently_updated = 0

        # ç»Ÿè®¡æ‰€æœ‰markdownæ–‡ä»¶
        for md_file in self.base_path.glob("**/*.md"):
            if "0-Inbox" in str(md_file):
                continue  # è·³è¿‡å¾…å¤„ç†æ–‡ä»¶

            total_files += 1

            # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡å‡†åŒ–å…ƒæ•°æ®
            content = md_file.read_text(encoding='utf-8', errors='ignore')
            if self._has_frontmatter(content):
                files_with_metadata += 1

            # ç»Ÿè®¡é“¾æ¥æ•°é‡
            links = re.findall(r'\[\[([^\]]+)\]\]', content)
            if links:
                files_with_links += 1
                total_links += len(links)

            # æ£€æŸ¥æœ€è¿‘æ›´æ–°ï¼ˆ30å¤©å†…ï¼‰
            file_age_days = (datetime.datetime.now().timestamp() - md_file.stat().st_mtime) / 86400
            if file_age_days <= 30:
                recently_updated += 1

        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        return {
            "metadata_coverage": (files_with_metadata / total_files * 100) if total_files > 0 else 0,
            "linked_files_ratio": (files_with_links / total_files * 100) if total_files > 0 else 0,
            "avg_links_per_file": (total_links / total_files) if total_files > 0 else 0,
            "content_activity": (recently_updated / total_files * 100) if total_files > 0 else 0,
            "overall_quality": 0  # ç¨åè®¡ç®—
        }

    def _analyze_efficiency(self) -> Dict[str, float]:
        """åˆ†ææ•ˆç‡æŒ‡æ ‡"""
        print("âš¡ åˆ†ææ•ˆç‡æŒ‡æ ‡...")

        # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µæ·»åŠ æ›´å¤šæ•ˆç‡æŒ‡æ ‡
        # ç›®å‰æä¾›åŸºç¡€çš„ç»“æ„ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•

        return {
            "processing_efficiency": 75.0,  # ç¤ºä¾‹å€¼ï¼Œéœ€è¦å®é™…æµ‹é‡
            "search_efficiency": 80.0,      # ç¤ºä¾‹å€¼ï¼Œéœ€è¦å®é™…æµ‹é‡
            "decision_speed": 70.0,         # ç¤ºä¾‹å€¼ï¼Œéœ€è¦å®é™…æµ‹é‡
            "overall_efficiency": 75.0      # ç¨åè®¡ç®—
        }

    def _analyze_growth(self) -> Dict[str, float]:
        """åˆ†ææˆé•¿æŒ‡æ ‡"""
        print("ğŸŒ± åˆ†ææˆé•¿æŒ‡æ ‡...")

        # ä»å†å²æ•°æ®ä¸­è®¡ç®—å¢é•¿è¶‹åŠ¿
        history = self._load_history()
        if len(history) < 2:
            return {
                "content_growth_rate": 0.0,
                "skill_development": 0.0,
                "goal_achievement": 0.0,
                "overall_growth": 0.0
            }

        latest = history[-1]
        previous = history[-2]

        # è®¡ç®—å†…å®¹å¢é•¿ç‡
        content_growth = ((latest["total_files"] - previous["total_files"]) /
                         previous["total_files"] * 100) if previous["total_files"] > 0 else 0

        return {
            "content_growth_rate": content_growth,
            "skill_development": 0.0,  # éœ€è¦ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥æˆ–ä»å…¶ä»–æ•°æ®æºè·å–
            "goal_achievement": 0.0,   # éœ€è¦ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥æˆ–ä»å…¶ä»–æ•°æ®æºè·å–
            "overall_growth": 0.0      # ç¨åè®¡ç®—
        }

    def _calculate_overall_health(self, para_stats: Dict, content_quality: Dict,
                                efficiency_metrics: Dict) -> float:
        """è®¡ç®—æ€»ä½“å¥åº·åº¦"""

        # PARAåˆ†å¸ƒå¥åº·åº¦ï¼ˆæƒé‡40%ï¼‰
        para_health = sum(stats["health"] * self.para_config[category]["weight"]
                         for category, stats in para_stats.items())

        # å†…å®¹è´¨é‡å¥åº·åº¦ï¼ˆæƒé‡30%ï¼‰
        quality_health = content_quality["overall_quality"]

        # æ•ˆç‡æŒ‡æ ‡å¥åº·åº¦ï¼ˆæƒé‡30%ï¼‰
        efficiency_health = efficiency_metrics["overall_efficiency"]

        overall = (para_health * 0.4 + quality_health * 0.3 + efficiency_health * 0.3)
        return round(overall, 1)

    def _calculate_range_score(self, value: float, min_val: float, max_val: float) -> float:
        """è®¡ç®—æ•°å€¼åœ¨ç†æƒ³èŒƒå›´å†…çš„å¾—åˆ†"""
        if min_val <= value <= max_val:
            return 100.0
        elif value < min_val:
            return max(0.0, 100.0 - (min_val - value) * 2)
        else:
            return max(0.0, 100.0 - (value - max_val) * 2)

    def _count_markdown_files(self, directory: str) -> int:
        """ç»Ÿè®¡æŒ‡å®šç›®å½•ä¸­çš„markdownæ–‡ä»¶æ•°é‡"""
        dir_path = self.base_path / directory
        if not dir_path.exists():
            return 0
        return len(list(dir_path.glob("**/*.md")))

    def _get_directory_size(self, directory: str) -> float:
        """è·å–ç›®å½•å¤§å°ï¼ˆMBï¼‰"""
        dir_path = self.base_path / directory
        if not dir_path.exists():
            return 0.0

        total_size = 0
        for file_path in dir_path.rglob("*"):
            if file_path.is_file():
                total_size += file_path.stat().st_size

        return round(total_size / (1024 * 1024), 2)  # è½¬æ¢ä¸ºMB

    def _has_frontmatter(self, content: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰frontmatter"""
        return bool(re.match(r'^---\n.*?\n---', content, re.DOTALL))

    def _load_history(self) -> List[Dict]:
        """åŠ è½½å†å²æ•°æ®"""
        if not self.history_file.exists():
            return []

        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return []

    def _save_history(self, metrics: SystemMetrics):
        """ä¿å­˜å†å²æ•°æ®"""
        history = self._load_history()

        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        metrics_dict = asdict(metrics)
        history.append(metrics_dict)

        # ä¿ç•™æœ€è¿‘12ä¸ªæœˆçš„æ•°æ®
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=365)
        history = [m for m in history if datetime.datetime.fromisoformat(m["date"]) > cutoff_date]

        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)

    def generate_report(self, metrics: SystemMetrics) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_date = datetime.datetime.now().strftime("%Y-%m-%d")
        report_file = self.reports_dir / f"detailed-metrics-{report_date}.md"

        # è®¡ç®—å„é¡¹è´¨é‡æŒ‡æ ‡çš„æ€»ä½“å¾—åˆ†
        metrics.content_quality["overall_quality"] = (
            metrics.content_quality["metadata_coverage"] * 0.3 +
            metrics.content_quality["linked_files_ratio"] * 0.3 +
            metrics.content_quality["avg_links_per_file"] * 5 +  # å¹³å‡é“¾æ¥æ•°*5ä½œä¸ºå¾—åˆ†
            metrics.content_quality["content_activity"] * 0.4
        )
        metrics.content_quality["overall_quality"] = min(100, metrics.content_quality["overall_quality"])

        metrics.efficiency_metrics["overall_efficiency"] = (
            metrics.efficiency_metrics["processing_efficiency"] * 0.4 +
            metrics.efficiency_metrics["search_efficiency"] * 0.3 +
            metrics.efficiency_metrics["decision_speed"] * 0.3
        )

        metrics.growth_metrics["overall_growth"] = (
            min(100, max(0, metrics.growth_metrics["content_growth_rate"])) * 0.4 +
            metrics.growth_metrics["skill_development"] * 0.3 +
            metrics.growth_metrics["goal_achievement"] * 0.3
        )

        report_content = f"""# TrevanBox è¯¦ç»†åº¦é‡åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {report_date}
**åˆ†æå™¨ç‰ˆæœ¬**: v2.0
**ç³»ç»Ÿè·¯å¾„**: {self.base_path}

## ğŸ“Š ç³»ç»Ÿæ¦‚è§ˆ

| æ ¸å¿ƒæŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|---------|------|------|
| æ€»æ–‡ä»¶æ•° | {metrics.total_files} | - |
| ç³»ç»Ÿå¥åº·åº¦ | {metrics.overall_health}/100 | {self._get_health_emoji(metrics.overall_health)} |
| å¾…å¤„ç†ç§¯å‹ | {metrics.pending_items} é¡¹ | {self._get_pending_emoji(metrics.pending_items, metrics.oldest_pending_age)} |
| æœ€æ—§ç§¯å‹å¹´é¾„ | {metrics.oldest_pending_age} å¤© | {self._get_age_emoji(metrics.oldest_pending_age)} |

## ğŸ“ PARAåˆ†å¸ƒè¯¦ç»†åˆ†æ

### åˆ†å¸ƒæ¦‚å†µ
{self._generate_para_table(metrics.para_distribution)}

### å¥åº·åº¦åˆ†æ
{self._generate_health_analysis(metrics.para_distribution)}

## ğŸ“ å†…å®¹è´¨é‡åˆ†æ

| è´¨é‡æŒ‡æ ‡ | æ•°å€¼ | ç†æƒ³èŒƒå›´ | çŠ¶æ€ |
|----------|------|----------|------|
| å…ƒæ•°æ®è¦†ç›–ç‡ | {metrics.content_quality['metadata_coverage']:.1f}% | >90% | {self._get_quality_emoji(metrics.content_quality['metadata_coverage'], 90)} |
| é“¾æ¥æ–‡ä»¶æ¯”ä¾‹ | {metrics.content_quality['linked_files_ratio']:.1f}% | >80% | {self._get_quality_emoji(metrics.content_quality['linked_files_ratio'], 80)} |
| å¹³å‡é“¾æ¥æ•°/æ–‡ä»¶ | {metrics.content_quality['avg_links_per_file']:.1f} | >3 | {self._get_quality_emoji(metrics.content_quality['avg_links_per_file'] * 20, 60)} |
| å†…å®¹æ´»è·ƒåº¦ | {metrics.content_quality['content_activity']:.1f}% | >40% | {self._get_quality_emoji(metrics.content_quality['content_activity'], 40)} |
| **æ€»ä½“è´¨é‡** | **{metrics.content_quality['overall_quality']:.1f}/100** | **>80** | **{self._get_health_emoji(metrics.content_quality['overall_quality'])}** |

## âš¡ æ•ˆç‡æŒ‡æ ‡åˆ†æ

| æ•ˆç‡æŒ‡æ ‡ | æ•°å€¼/100 | çŠ¶æ€ | å»ºè®® |
|----------|----------|------|------|
| å¤„ç†æ•ˆç‡ | {metrics.efficiency_metrics['processing_efficiency']:.1f} | {self._get_health_emoji(metrics.efficiency_metrics['processing_efficiency'])} | {self._get_efficiency_advice('processing', metrics.efficiency_metrics['processing_efficiency'])} |
| æœç´¢æ•ˆç‡ | {metrics.efficiency_metrics['search_efficiency']:.1f} | {self._get_health_emoji(metrics.efficiency_metrics['search_efficiency'])} | {self._get_efficiency_advice('search', metrics.efficiency_metrics['search_efficiency'])} |
| å†³ç­–é€Ÿåº¦ | {metrics.efficiency_metrics['decision_speed']:.1f} | {self._get_health_emoji(metrics.efficiency_metrics['decision_speed'])} | {self._get_efficiency_advice('decision', metrics.efficiency_metrics['decision_speed'])} |
| **æ€»ä½“æ•ˆç‡** | **{metrics.efficiency_metrics['overall_efficiency']:.1f}** | **{self._get_health_emoji(metrics.efficiency_metrics['overall_efficiency'])}** | **ç»¼åˆä¼˜åŒ–å„é¡¹æ•ˆç‡æŒ‡æ ‡** |

## ğŸŒ± æˆé•¿æŒ‡æ ‡åˆ†æ

| æˆé•¿æŒ‡æ ‡ | æ•°å€¼ | è¶‹åŠ¿ | è¯´æ˜ |
|----------|------|------|------|
| å†…å®¹å¢é•¿ç‡ | {metrics.growth_metrics['content_growth_rate']:.1f}% | {self._get_trend_emoji(metrics.growth_metrics['content_growth_rate'])} | ç›¸å¯¹ä¸ŠæœŸçš„å†…å®¹å¢é•¿ |
| æŠ€èƒ½å‘å±• | {metrics.growth_metrics['skill_development']:.1f}/100 | {self._get_health_emoji(metrics.growth_metrics['skill_development'])} | ä¸ªäººæŠ€èƒ½æå‡æƒ…å†µ |
| ç›®æ ‡è¾¾æˆ | {metrics.growth_metrics['goal_achievement']:.1f}/100 | {self._get_health_emoji(metrics.growth_metrics['goal_achievement'])} | ç›®æ ‡å®Œæˆæƒ…å†µ |
| **æ€»ä½“æˆé•¿** | **{metrics.growth_metrics['overall_growth']:.1f}/100** | **{self._get_health_emoji(metrics.growth_metrics['overall_growth'])}** | **ç»¼åˆæˆé•¿è¯„ä¼°** |

## ğŸ¯ ä¸ªæ€§åŒ–å»ºè®®

### ç«‹å³è¡ŒåŠ¨ï¼ˆæœ¬å‘¨å†…ï¼‰
{self._generate_immediate_actions(metrics)}

### çŸ­æœŸæ”¹è¿›ï¼ˆæœ¬æœˆå†…ï¼‰
{self._generate_short_term_improvements(metrics)}

### é•¿æœŸä¼˜åŒ–ï¼ˆæœ¬å­£åº¦ï¼‰
{self._generate_long_term_optimizations(metrics)}

## ğŸ“ˆ å†å²è¶‹åŠ¿

> *éœ€è¦ç§¯ç´¯æ›´å¤šå†å²æ•°æ®æ‰èƒ½ç”Ÿæˆè¶‹åŠ¿å›¾è¡¨*

## ğŸ“‹ æ•°æ®å¯¼å‡º

### å®Œæ•´æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
```json
{json.dumps(asdict(metrics), indent=2, ensure_ascii=False)}
```

---

**æŠ¥å‘Šç”Ÿæˆå™¨**: TrevanBox Metrics Analyzer v2.0
**ä¸‹æ¬¡åˆ†ææ—¶é—´**: {(datetime.datetime.now() + datetime.timedelta(days=7)).strftime('%Y-%m-%d')}
**é…ç½®æ–‡ä»¶**: {self.base_path / "scripts" / "metrics_config.json"}
"""

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)

        return str(report_file)

    def _get_health_emoji(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°è¿”å›å¥åº·åº¦emoji"""
        if score >= 80:
            return "ğŸŸ¢ ä¼˜ç§€"
        elif score >= 60:
            return "ğŸŸ¡ è‰¯å¥½"
        else:
            return "ğŸ”´ éœ€å…³æ³¨"

    def _get_pending_emoji(self, count: int, age: int) -> str:
        """æ ¹æ®ç§¯å‹æƒ…å†µè¿”å›emoji"""
        if count <= 5 and age <= 3:
            return "ğŸŸ¢ æ­£å¸¸"
        elif count <= 15 and age <= 7:
            return "ğŸŸ¡ éœ€å¤„ç†"
        else:
            return "ğŸ”´ ç§¯å‹ä¸¥é‡"

    def _get_age_emoji(self, age: int) -> str:
        """æ ¹æ®å¹´é¾„è¿”å›emoji"""
        if age <= 3:
            return "ğŸŸ¢ æ­£å¸¸"
        elif age <= 7:
            return "ğŸŸ¡ éœ€å…³æ³¨"
        else:
            return "ğŸ”´ ä¸¥é‡ç§¯å‹"

    def _get_quality_emoji(self, value: float, threshold: float) -> str:
        """æ ¹æ®è´¨é‡æŒ‡æ ‡è¿”å›emoji"""
        if value >= threshold:
            return "ğŸŸ¢"
        elif value >= threshold * 0.8:
            return "ğŸŸ¡"
        else:
            return "ğŸ”´"

    def _get_trend_emoji(self, growth_rate: float) -> str:
        """æ ¹æ®å¢é•¿ç‡è¿”å›è¶‹åŠ¿emoji"""
        if growth_rate > 5:
            return "ğŸ“ˆ å¿«é€Ÿå¢é•¿"
        elif growth_rate > 0:
            return "ğŸ“Š ç¨³æ­¥å¢é•¿"
        elif growth_rate > -5:
            return "â¡ï¸ åŸºæœ¬ç¨³å®š"
        else:
            return "ğŸ“‰ éœ€è¦å…³æ³¨"

    def _get_efficiency_advice(self, metric_type: str, score: float) -> str:
        """è·å–æ•ˆç‡å»ºè®®"""
        advice_map = {
            'processing': {
                (80, 100): "ä¿æŒå½“å‰å¤„ç†æµç¨‹",
                (60, 80): "ä¼˜åŒ–AIé¢„å¤„ç†é…ç½®",
                (0, 60): "é‡æ–°è®¾è®¡å¤„ç†æµç¨‹"
            },
            'search': {
                (80, 100): "æœç´¢æ•ˆç‡ä¼˜ç§€",
                (60, 80): "æ”¹è¿›æ ‡ç­¾å’Œé“¾æ¥ç³»ç»Ÿ",
                (0, 60): "å­¦ä¹ é«˜çº§æœç´¢æŠ€å·§"
            },
            'decision': {
                (80, 100): "å†³ç­–æ•ˆç‡å¾ˆé«˜",
                (60, 80): "åŠ å¼ºå†³ç­–æ¡†æ¶ä½¿ç”¨",
                (0, 60): "å»ºç«‹æ ‡å‡†åŒ–å†³ç­–æµç¨‹"
            }
        }

        for range_tuple, advice in advice_map[metric_type].items():
            if range_tuple[0] <= score <= range_tuple[1]:
                return advice
        return "éœ€è¦æ·±åº¦ä¼˜åŒ–"

    def _generate_para_table(self, para_stats: Dict) -> str:
        """ç”ŸæˆPARAåˆ†å¸ƒè¡¨æ ¼"""
        table = "| ç±»åˆ« | æ–‡ä»¶æ•° | å æ¯” | å¤§å°(MB) | å¥åº·åº¦ | çŠ¶æ€ |\n"
        table += "|------|--------|------|----------|--------|------|\n"

        for category, stats in para_stats.items():
            category_name = category.split('-')[1]  # å»æ‰å‰ç¼€æ•°å­—
            status_emoji = self._get_health_emoji(stats["health"])
            table += f"| {category_name} | {stats['count']} | {stats['ratio']:.1f}% | {stats['size_mb']:.1f} | {stats['health']:.1f}/100 | {status_emoji} |\n"

        return table

    def _generate_health_analysis(self, para_stats: Dict) -> str:
        """ç”Ÿæˆå¥åº·åº¦åˆ†æ"""
        analysis = []

        for category, stats in para_stats.items():
            category_name = category.split('-')[1]
            health = stats["health"]
            ratio = stats["ratio"]

            if health < 60:
                analysis.append(f"- **{category_name}åˆ†å¸ƒå¼‚å¸¸**ï¼šå æ¯”{ratio:.1f}%ï¼Œå¥åº·åº¦{health:.1f}/100ï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–")
            elif health < 80:
                analysis.append(f"- **{category_name}åˆ†å¸ƒä¸€èˆ¬**ï¼šå æ¯”{ratio:.1f}%ï¼Œå»ºè®®é€‚å½“è°ƒæ•´")
            else:
                analysis.append(f"- **{category_name}åˆ†å¸ƒè‰¯å¥½**ï¼šå æ¯”{ratio:.1f}%ï¼Œç»§ç»­ä¿æŒ")

        return "\n".join(analysis)

    def _generate_immediate_actions(self, metrics: SystemMetrics) -> str:
        """ç”Ÿæˆç«‹å³è¡ŒåŠ¨å»ºè®®"""
        actions = []

        if metrics.oldest_pending_age > 7:
            actions.append(f"- å¤„ç†ç§¯å‹è¶…è¿‡{metrics.oldest_pending_age}å¤©çš„å¾…å¤„ç†å†…å®¹")

        if metrics.pending_items > 15:
            actions.append(f"- æ¸…ç†{metrics.pending_items}é¡¹å¾…å¤„ç†å†…å®¹")

        if metrics.overall_health < 60:
            actions.append("- é‡ç‚¹æå‡ç³»ç»Ÿå¥åº·åº¦")

        if metrics.content_quality['metadata_coverage'] < 80:
            actions.append("- è¡¥å……ç¼ºå¤±çš„å…ƒæ•°æ®")

        return "\n".join(actions) if actions else "- ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰ä½¿ç”¨ä¹ æƒ¯"

    def _generate_short_term_improvements(self, metrics: SystemMetrics) -> str:
        """ç”ŸæˆçŸ­æœŸæ”¹è¿›å»ºè®®"""
        improvements = []

        # PARAåˆ†å¸ƒä¼˜åŒ–
        for category, stats in metrics.para_distribution.items():
            if stats["health"] < 80:
                category_name = category.split('-')[1]
                improvements.append(f"- ä¼˜åŒ–{category_name}åˆ†å¸ƒï¼Œå½“å‰å æ¯”{stats['ratio']:.1f}%")

        # å†…å®¹è´¨é‡æå‡
        if metrics.content_quality['linked_files_ratio'] < 80:
            improvements.append("- å¢åŠ å†…å®¹é—´çš„é“¾æ¥å’Œå…³è”")

        if metrics.content_quality['avg_links_per_file'] < 3:
            improvements.append("- æå‡å¹³å‡é“¾æ¥å¯†åº¦")

        return "\n".join(improvements) if improvements else "- å„é¡¹æŒ‡æ ‡è‰¯å¥½ï¼Œç»§ç»­ç²¾ç»†åŒ–ä½¿ç”¨"

    def _generate_long_term_optimizations(self, metrics: SystemMetrics) -> str:
        """ç”Ÿæˆé•¿æœŸä¼˜åŒ–å»ºè®®"""
        optimizations = []

        optimizations.append("- å»ºç«‹å®šæœŸå›é¡¾å’Œä¼˜åŒ–æœºåˆ¶")
        optimizations.append("- æ·±åº¦åº”ç”¨PARAæ–¹æ³•è®ºåˆ°æ›´å¤šç”Ÿæ´»åœºæ™¯")
        optimizations.append("- æ¢ç´¢AIå·¥å…·çš„æ·±åº¦é›†æˆ")
        optimizations.append("- å»ºç«‹ä¸ªäººçŸ¥è¯†å›¾è°±")

        return "\n".join(optimizations)

    def run_analysis(self, save_history: bool = True, generate_report: bool = True) -> str:
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹TrevanBoxç³»ç»Ÿåº¦é‡åˆ†æ...")

        # åˆ†æç³»ç»Ÿ
        metrics = self.analyze_system()

        # ä¿å­˜å†å²æ•°æ®
        if save_history:
            self._save_history(metrics)
            print("ğŸ’¾ å†å²æ•°æ®å·²ä¿å­˜")

        # ç”ŸæˆæŠ¥å‘Š
        report_path = ""
        if generate_report:
            report_path = self.generate_report(metrics)
            print(f"ğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

        # æ˜¾ç¤ºå…³é”®ç»“æœ
        print("\n" + "="*50)
        print("ğŸ“‹ åˆ†æç»“æœæ‘˜è¦")
        print("="*50)
        print(f"æ€»ä½“å¥åº·åº¦: {metrics.overall_health}/100 {self._get_health_emoji(metrics.overall_health)}")
        print(f"æ–‡ä»¶æ€»æ•°: {metrics.total_files}")
        print(f"å¾…å¤„ç†ç§¯å‹: {metrics.pending_items} é¡¹ (æœ€æ—§: {metrics.oldest_pending_age} å¤©)")
        print(f"å†…å®¹è´¨é‡: {metrics.content_quality['overall_quality']:.1f}/100")
        print(f"ä½¿ç”¨æ•ˆç‡: {metrics.efficiency_metrics['overall_efficiency']:.1f}/100")

        return report_path

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="TrevanBox é«˜çº§åº¦é‡åˆ†æå·¥å…·")
    parser.add_argument("--base-path", default=".", help="TrevanBoxç³»ç»Ÿæ ¹ç›®å½•è·¯å¾„")
    parser.add_argument("--no-save", action="store_true", help="ä¸ä¿å­˜å†å²æ•°æ®")
    parser.add_argument("--no-report", action="store_true", help="ä¸ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š")
    parser.add_argument("--quiet", action="store_true", help="é™é»˜æ¨¡å¼ï¼Œåªè¾“å‡ºç»“æœ")

    args = parser.parse_args()

    try:
        analyzer = TrevanBoxMetricsAnalyzer(args.base_path)
        report_path = analyzer.run_analysis(
            save_history=not args.no_save,
            generate_report=not args.no_report
        )

        if not args.quiet and report_path:
            print(f"\nğŸ“„ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: {report_path}")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())